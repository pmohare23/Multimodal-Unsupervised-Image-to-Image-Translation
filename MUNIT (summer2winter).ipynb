{"cells":[{"cell_type":"code","source":["#https://drive.google.com/file/d/18DBHptZfYZw4wHhrvdKf9qNmrhFJ59EU/view?usp=sharing\n"],"metadata":{"id":"C9WqX7KKIP3G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670818434928,"user_tz":300,"elapsed":12456,"user":{"displayName":"Pratik Mohare","userId":"13234718444931704766"}},"outputId":"726ad53e-cf92-4171-d5a7-9555fecac738"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.8.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n","/usr/local/lib/python3.8/dist-packages/gdown/cli.py:127: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=18DBHptZfYZw4wHhrvdKf9qNmrhFJ59EU\n","To: /content/MUNIT_summer2winter.zip\n","100% 6.97k/6.97k [00:00<00:00, 13.1MB/s]\n","Archive:  MUNIT_summer2winter.zip\n","  inflating: models.py               \n","  inflating: munit.py                \n","  inflating: utils.py                \n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t36cithOKItU","colab":{"base_uri":"https://localhost:8080/","height":359},"executionInfo":{"status":"error","timestamp":1670818800200,"user_tz":300,"elapsed":489,"user":{"displayName":"Pratik Mohare","userId":"13234718444931704766"}},"outputId":"b561a23d-b02f-4aba-d253-cf3c5d76f842"},"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(b1=0.5, b2=0.999, batch_size=1, channels=3, checkpoint_interval=-1, dataset_name='summer2winter_yosemite', decay_epoch=100, dim=64, epoch=25, img_height=128, img_width=128, lr=0.0001, n_cpu=8, n_downsample=2, n_epochs=200, n_residual=4, sample_interval=200, style_dim=8)\n"]},{"output_type":"error","ename":"FileExistsError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-284f462456bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved_models/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss_output/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/lib/python3.8/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'test'"]}],"source":["import argparse\n","import os\n","import numpy as np\n","import math\n","import itertools\n","import datetime\n","import time\n","import sys\n","\n","import torchvision.transforms as transforms\n","from torchvision.utils import save_image\n","\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torch.autograd import Variable\n","\n","from models import *\n","from utils import *\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument(\"--epoch\", type=int, default=0, help=\"epoch to start training from\")\n","parser.add_argument(\"--n_epochs\", type=int, default=200, help=\"number of epochs of training\")\n","parser.add_argument(\"--dataset_name\", type=str, default=\"summer2winter_yosemite\", help=\"name of the dataset\")\n","parser.add_argument(\"--batch_size\", type=int, default=1, help=\"size of the batches\")\n","parser.add_argument(\"--lr\", type=float, default=0.0001, help=\"adam: learning rate\")\n","parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n","parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n","parser.add_argument(\"--decay_epoch\", type=int, default=100, help=\"epoch from which to start lr decay\")\n","parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of cpu threads to use during batch generation\")\n","parser.add_argument(\"--img_height\", type=int, default=128, help=\"size of image height\")\n","parser.add_argument(\"--img_width\", type=int, default=128, help=\"size of image width\")\n","parser.add_argument(\"--channels\", type=int, default=3, help=\"number of image channels\")\n","parser.add_argument(\"--sample_interval\", type=int, default=200, help=\"interval saving generator samples\")\n","parser.add_argument(\"--checkpoint_interval\", type=int, default=-1, help=\"interval between saving model checkpoints\")\n","parser.add_argument(\"--n_downsample\", type=int, default=2, help=\"number downsampling layers in encoder\")\n","parser.add_argument(\"--n_residual\", type=int, default=4, help=\"number of residual blocks in encoder / decoder\")\n","parser.add_argument(\"--dim\", type=int, default=64, help=\"number of filters in first encoder layer\")\n","parser.add_argument(\"--style_dim\", type=int, default=8, help=\"dimensionality of the style code\")\n","opt = parser.parse_args([\"--epoch\",\"25\"])\n","print(opt)\n","\n","cuda = torch.cuda.is_available()\n","\n","# Create sample and checkpoint directories\n","os.makedirs(\"images/%s\" % opt.dataset_name, exist_ok=True)\n","os.makedirs(\"saved_models/%s\" % opt.dataset_name, exist_ok=True)\n","os.makedirs(\"loss_output/%s\" % opt.dataset_name, exist_ok=True)\n","os.makedirs(\"test\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y9u_LNKIRXxh"},"outputs":[],"source":["url=\"https://s3.amazonaws.com/video.udacity-data.com/topher/2018/November/5be66e78_summer2winter-yosemite/summer2winter-yosemite.zip\"\n","!wget $url\n","!unzip summer2winter-yosemite.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z_GdEjfHSpZw","outputId":"eb1cc4ec-0935-49a4-dea0-33e63be0a92a","executionInfo":{"status":"ok","timestamp":1670696796979,"user_tz":300,"elapsed":1858,"user":{"displayName":"Pratik Mohare","userId":"13234718444931704766"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["criterion_recon = torch.nn.L1Loss()\n","\n","# Initialize encoders, generators and discriminators\n","Enc1 = Encoder(dim=opt.dim, n_downsample=opt.n_downsample, n_residual=opt.n_residual, style_dim=opt.style_dim)\n","Dec1 = Decoder(dim=opt.dim, n_upsample=opt.n_downsample, n_residual=opt.n_residual, style_dim=opt.style_dim)\n","Enc2 = Encoder(dim=opt.dim, n_downsample=opt.n_downsample, n_residual=opt.n_residual, style_dim=opt.style_dim)\n","Dec2 = Decoder(dim=opt.dim, n_upsample=opt.n_downsample, n_residual=opt.n_residual, style_dim=opt.style_dim)\n","D1 = MultiDiscriminator()\n","D2 = MultiDiscriminator()\n","\n","if cuda:\n","    Enc1 = Enc1.cuda()\n","    Dec1 = Dec1.cuda()\n","    Enc2 = Enc2.cuda()\n","    Dec2 = Dec2.cuda()\n","    D1 = D1.cuda()\n","    D2 = D2.cuda()\n","    criterion_recon.cuda()\n","\n","if opt.epoch != 0:\n","    # Load pretrained models\n","    Enc1.load_state_dict(torch.load(\"saved_models/%s/Enc1_%d.pth\" % (opt.dataset_name, opt.epoch)))\n","    Dec1.load_state_dict(torch.load(\"saved_models/%s/Dec1_%d.pth\" % (opt.dataset_name, opt.epoch)))\n","    Enc2.load_state_dict(torch.load(\"saved_models/%s/Enc2_%d.pth\" % (opt.dataset_name, opt.epoch)))\n","    Dec2.load_state_dict(torch.load(\"saved_models/%s/Dec2_%d.pth\" % (opt.dataset_name, opt.epoch)))\n","    D1.load_state_dict(torch.load(\"saved_models/%s/D1_%d.pth\" % (opt.dataset_name, opt.epoch)))\n","    D2.load_state_dict(torch.load(\"saved_models/%s/D2_%d.pth\" % (opt.dataset_name, opt.epoch)))\n","else:\n","    # Initialize weights\n","    Enc1.apply(weights_init_normal)\n","    Dec1.apply(weights_init_normal)\n","    Enc2.apply(weights_init_normal)\n","    Dec2.apply(weights_init_normal)\n","    D1.apply(weights_init_normal)\n","    D2.apply(weights_init_normal)\n","\n","# Loss weights\n","lambda_gan = 5\n","lambda_id = 10\n","lambda_style = 1\n","lambda_cont = 20\n","lambda_cyc = 10\n","\n","# Optimizers\n","optimizer_G = torch.optim.Adam(\n","    itertools.chain(Enc1.parameters(), Dec1.parameters(), Enc2.parameters(), Dec2.parameters()),\n","    lr=opt.lr,\n","    betas=(opt.b1, opt.b2),\n",")\n","optimizer_D1 = torch.optim.Adam(D1.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n","optimizer_D2 = torch.optim.Adam(D2.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n","\n","# Learning rate update schedulers\n","lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(\n","    optimizer_G, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step\n",")\n","lr_scheduler_D1 = torch.optim.lr_scheduler.LambdaLR(\n","    optimizer_D1, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step\n",")\n","lr_scheduler_D2 = torch.optim.lr_scheduler.LambdaLR(\n","    optimizer_D2, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step\n",")\n","\n","Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n","\n","# Configure dataloaders\n","transforms_ = [\n","    transforms.Resize((opt.img_height, opt.img_width), transforms.InterpolationMode.BICUBIC),\n","    transforms.ToTensor(),\n","    #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","]\n","\n","dataloader = DataLoader(\n","    ImageDataset(opt.dataset_name, transforms_=transforms_),\n","    batch_size=opt.batch_size,\n","    shuffle=True,\n","    num_workers=opt.n_cpu,\n",")\n","\n","val_dataloader = DataLoader(\n","    ImageDataset(opt.dataset_name, transforms_=transforms_, mode=\"val\"),\n","    batch_size=5,\n","    shuffle=True,\n","    num_workers=1,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2yXof5WwKZOx"},"outputs":[],"source":["# Adversarial ground truths\n","valid = 1\n","fake = 0\n","\n","prev_time = time.time()\n","\n","# keep track of losses\n","G_losses = []\n","D_losses = []\n","\n","lambdas = (lambda_gan, lambda_id, lambda_style, lambda_cont, lambda_cyc)\n","\n","for epoch in range(opt.epoch, opt.n_epochs+1):\n","    for i, batch in enumerate(dataloader):\n","\n","\n","        # Set model input\n","        X1 = Variable(batch[\"A\"].type(Tensor))\n","        X2 = Variable(batch[\"B\"].type(Tensor))\n","\n","        # Sampled style codes\n","        # style_1 = Variable(torch.randn(X1.size(0), opt.style_dim, 1, 1).type(Tensor))\n","        # style_2 = Variable(torch.randn(X1.size(0), opt.style_dim, 1, 1).type(Tensor))\n","\n","        # -------------------------------\n","        #  Train Encoders and Generators\n","        # -------------------------------\n","\n","        optimizer_G.zero_grad()\n","\n","        # Get shared latent representation\n","        c_code_1, s_code_1 = Enc1(X1)\n","        c_code_2, s_code_2 = Enc2(X2)\n","\n","        # Reconstruct images\n","        X11 = Dec1(c_code_1, s_code_1)\n","        X22 = Dec2(c_code_2, s_code_2)\n","\n","        # Translate images\n","        X21 = Dec1(c_code_2, s_code_1)\n","        X12 = Dec2(c_code_1, s_code_2)\n","\n","        # Cycle translation\n","        c_code_21, s_code_21 = Enc1(X21)\n","        c_code_12, s_code_12 = Enc2(X12)\n","        X121 = Dec1(c_code_12, s_code_1) if lambda_cyc > 0 else 0\n","        X212 = Dec2(c_code_21, s_code_2) if lambda_cyc > 0 else 0\n","\n","        # Losses\n","        loss_GAN_1 = lambda_gan * D1.compute_loss(X21, valid)\n","        loss_GAN_2 = lambda_gan * D2.compute_loss(X12, valid)\n","        loss_ID_1 = lambda_id * criterion_recon(X11, X1)\n","        loss_ID_2 = lambda_id * criterion_recon(X22, X2)\n","        loss_s_1 = lambda_style * criterion_recon(s_code_21, s_code_1)\n","        loss_s_2 = lambda_style * criterion_recon(s_code_12, s_code_2)\n","        loss_c_1 = lambda_cont * criterion_recon(c_code_12, c_code_1.detach())\n","        loss_c_2 = lambda_cont * criterion_recon(c_code_21, c_code_2.detach())\n","        loss_cyc_1 = lambda_cyc * criterion_recon(X121, X1) if lambda_cyc > 0 else 0\n","        loss_cyc_2 = lambda_cyc * criterion_recon(X212, X2) if lambda_cyc > 0 else 0\n","\n","        # Total loss\n","        loss_G = (\n","            loss_GAN_1\n","            + loss_GAN_2\n","            + loss_ID_1\n","            + loss_ID_2\n","            + loss_s_1\n","            + loss_s_2\n","            + loss_c_1\n","            + loss_c_2\n","            + loss_cyc_1\n","            + loss_cyc_2\n","        )\n","\n","        loss_G.backward()\n","        optimizer_G.step()\n","\n","        # -----------------------\n","        #  Train Discriminator 1\n","        # -----------------------\n","\n","        optimizer_D1.zero_grad()\n","\n","        loss_D1 = D1.compute_loss(X1, valid) + D1.compute_loss(X21.detach(), fake)\n","\n","        loss_D1.backward()\n","        optimizer_D1.step()\n","\n","        # -----------------------\n","        #  Train Discriminator 2\n","        # -----------------------\n","\n","        optimizer_D2.zero_grad()\n","\n","        loss_D2 = D2.compute_loss(X2, valid) + D2.compute_loss(X12.detach(), fake)\n","\n","        loss_D2.backward()\n","        optimizer_D2.step()\n","\n","        # --------------\n","        #  Log Progress\n","        # --------------\n","\n","        # Determine approximate time left\n","        batches_done = epoch * len(dataloader) + i\n","        batches_left = opt.n_epochs * len(dataloader) - batches_done\n","        time_left = datetime.timedelta(seconds=batches_left * (time.time() - prev_time))\n","        prev_time = time.time()\n","        # Print log\n","        sys.stdout.write(\n","            \"\\r[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f] ETA: %s\"\n","            % (epoch, opt.n_epochs, i, len(dataloader), (loss_D1 + loss_D2).item(), loss_G.item(), time_left)\n","        )\n","\n","        # If at sample interval save image\n","        if batches_done % opt.sample_interval == 0:\n","            sample_images(batches_done, lambdas, val_dataloader, opt, Tensor, Enc1, Dec2)\n","\n","    G_losses.append(loss_G.item())\n","    D_losses.append((loss_D1 + loss_D2).item())\n","    \n","    # Update learning rates\n","    lr_scheduler_G.step()\n","    lr_scheduler_D1.step()\n","    lr_scheduler_D2.step()\n","\n","    if opt.checkpoint_interval != -1 and epoch % opt.checkpoint_interval == 0:\n","        # Save model checkpoints\n","        torch.save(Enc1.state_dict(), \"saved_models/%s/Enc1_%d.pth\" % (opt.dataset_name, epoch))\n","        torch.save(Dec1.state_dict(), \"saved_models/%s/Dec1_%d.pth\" % (opt.dataset_name, epoch))\n","        torch.save(Enc2.state_dict(), \"saved_models/%s/Enc2_%d.pth\" % (opt.dataset_name, epoch))\n","        torch.save(Dec2.state_dict(), \"saved_models/%s/Dec2_%d.pth\" % (opt.dataset_name, epoch))\n","        torch.save(D1.state_dict(), \"saved_models/%s/D1_%d.pth\" % (opt.dataset_name, epoch))\n","        torch.save(D2.state_dict(), \"saved_models/%s/D2_%d.pth\" % (opt.dataset_name, epoch))\n","\n","loss_output(G_losses, D_losses, epoch, opt, lambdas)          "]},{"cell_type":"markdown","source":["Video Translation"],"metadata":{"id":"XqXbeRbd_rn_"}},{"cell_type":"code","source":["!mkdir vidframes"],"metadata":{"id":"4ZN7EtOcUqN2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2 as cv\n","vid_file= !ls *.mp4\n","totalvidframes = 0\n","vid = cv.VideoCapture(vid_file[0])\n","# vid_writer = cv.VideoWriter(\"gen_\"+vid_file, cv.VideoWriter_fourcc(*'mp4v'), vid.get(cv.CAP_PROP_FPS), (round(vid.get(cv.CAP_PROP_FRAME_WIDTH)),round(vid.get(cv.CAP_PROP_FRAME_HEIGHT))))\n","while (True):\n","    suc, vfr = vid.read()\n","    if not suc:\n","        break\n","    cv.imwrite(f'test/frame_{totalvidframes}.jpg', vfr)\n","    totalvidframes+=1\n","fps=vid.get(cv.CAP_PROP_FPS)\n","s1,s2=vid.get(cv.CAP_PROP_FRAME_WIDTH),vid.get(cv.CAP_PROP_FRAME_HEIGHT)\n","vid.release()"],"metadata":{"id":"d7vclC_V5Zr3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_dataloader = DataLoader(\n","    ImageDataset(opt.dataset_name, transforms_=transforms_, mode=\"test\"),\n","    batch_size=1,\n","    shuffle=False,\n","    num_workers=1,\n",")\n","\n","iterator=iter(test_dataloader)\n","for i in range(test_dataloader.__len__()):\n","\n","    imgs = next(iterator)    \n","    Xog = imgs['A'].resize(3,512,512)\n","    X1= Xog.unsqueeze(0).repeat(opt.style_dim, 1, 1, 1)\n","    X1 = Variable(X1.type(Tensor))\n","    c_code_1,_= Enc1(X1)\n","    \n","    s_code = np.random.uniform(-1, 1, (opt.style_dim, opt.style_dim))\n","    s_code = Variable(Tensor(s_code))\n","        \n","    X12 = Dec2(c_code_1, s_code)\n","    # Concatenate samples horisontally\n","    X12 = torch.cat([x for x in X12.data.cpu()], -1)\n","    img_out = torch.cat((Xog, X12), -1).unsqueeze(0)\n","    save_image(img_out, \"vidframes/gen_\"+imgs['B'][0].split('/')[1])"],"metadata":{"id":"2XV_WU8VVHB1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vid_writer = cv.VideoWriter(\"out_gen_\"+vid_file[0], cv.VideoWriter_fourcc(*'mp4v'), fps, (4608,512))\n","for i in range(test_dataloader.__len__()):\n","    cap=cv.VideoCapture(\"vidframes/gen_frame_\"+str(i)+\".jpg\")\n","    ret, frame=cap.read()\n","    vid_writer.write(frame)\n","    cap.release()\n","vid_writer.release()"],"metadata":{"id":"j9Dq_V-y8KJy"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNeN4oZLYIafUspAdLaCag2"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}